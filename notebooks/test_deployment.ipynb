{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Deployment Test\n",
    "\n",
    "The following notebook allows us to manually test a model deployment endpoint with a test image and visulaise the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Model Endpoint \n",
    "Choose which endpoint that will be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Endpoint\n",
    "Set the AML endpoint to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint url is found in the AML studio. You must append the probaility argument in the form url/score?prob=0.5\n",
    "endpoint = ''\n",
    "\n",
    "enable_auth = True\n",
    "auth = ''\n",
    "\n",
    "# Test image path\n",
    "test_img = f'./test_image.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open(test_img, 'rb').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the endpoint\n",
    "import requests\n",
    "import json\n",
    "\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "if enable_auth:\n",
    "    headers['Authorization']=f'Bearer {auth}'\n",
    "\n",
    "resp = requests.post(endpoint, img, headers=headers)\n",
    "print(resp)\n",
    "results = resp.text\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Present Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np=mpimg.imread(test_img)\n",
    "img = Image.fromarray(img_np.astype('uint8'),'RGB')\n",
    "x, y = img.size\n",
    "IMAGE_SIZE = (x/50,y/50)\n",
    "plt.figure(figsize=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "# Display the image\n",
    "ax.imshow(img_np)\n",
    "\n",
    "# draw box and label for each detection \n",
    "detections = json.loads(results)\n",
    "for detect in detections:\n",
    "    label = detect['label']\n",
    "    box = detect['bounding_box']\n",
    "    ymin, xmin, ymax, xmax = box[0], box[1], box[2], box[3]\n",
    "    topleft_x, topleft_y = x * xmin, y * ymin\n",
    "    width, height = x * (xmax - xmin), y * (ymax - ymin)\n",
    "    print('{}: {}, {}, {}, {}'.format(detect['label'], topleft_x, topleft_y, width, height))\n",
    "\n",
    "    color = 'white'\n",
    "    rect = patches.Rectangle((topleft_x, topleft_y), width, height, \n",
    "                             linewidth=2, edgecolor=color,facecolor='none')\n",
    "\n",
    "    ax.add_patch(rect)\n",
    "    plt.text(topleft_x, topleft_y, label, color=color)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Mask Result\n",
    "\n",
    "For mask_rcnn based models, the model generates for each input image multiple masks of fixed sizes. One needs to resize the masks to its original shape, put them into the right positions and generate contour polygons from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.transform import resize\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "\n",
    "def unmold_mask(mask, bbox, image_shape):\n",
    "    \"\"\"\n",
    "    Converts a mask generated by the neural network to a format similar to its original shape\n",
    "    \n",
    "    mask: [height, width] of type float. A small, typically 28x28 mask.\n",
    "    bbox: [y1, x1, y2, x2]. The box to fit the mask in.\n",
    "    Returns a binary mask with the same size as the original image.\n",
    "    \"\"\"\n",
    "    threshold = 0.5\n",
    "    y1, x1, y2, x2 = bbox\n",
    "    mask = resize(mask, (y2 - y1, x2 - x1))\n",
    "    mask = np.where(mask >= threshold, 1, 0).astype(np.bool)\n",
    "\n",
    "    # Put the mask in the right location.\n",
    "    full_mask = np.zeros(image_shape[:2], dtype=np.bool)\n",
    "    full_mask[y1:y2, x1:x2] = mask\n",
    "    return full_mask\n",
    "\n",
    "\n",
    "def visualize_polygon(img_path, polygons, color=(255,0,0,128)):\n",
    "    img = Image.open(img_path)\n",
    "    img2 = img.copy()\n",
    "    draw = ImageDraw.Draw(img2)\n",
    "    for polygon in polygons:\n",
    "        draw.polygon(tuple(polygon), fill=color)\n",
    "    img3 = Image.blend(img, img2, 0.5)\n",
    "    img3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw polygons for each detection\n",
    "detections = json.loads(results)\n",
    "polygons = []\n",
    "for detect in detections:\n",
    "    label = detect['label']\n",
    "    box = detect['bounding_box']\n",
    "    ymin, xmin, ymax, xmax = box[0], box[1], box[2], box[3]\n",
    "    topleft_x, topleft_y, width, height = x * xmin, y * ymin, x * (xmax - xmin), y * (ymax - ymin)  # De-normalizing\n",
    "\n",
    "    # extract and resize the predicted mask\n",
    "    mask = detect['mask']\n",
    "    mask_np = np.array(mask)\n",
    "    mask = unmold_mask(mask=mask_np, bbox=[int(topleft_y), int(topleft_x), int(topleft_y)+int(height), int(topleft_x)+int(width)], image_shape=(y,x))\n",
    "    mask_img = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "    mask_img.show()\n",
    "    \n",
    "    # extract segmentation polygons based on mask contour\n",
    "    contours, _ = cv2.findContours((mask * 255).astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for contour in contours:\n",
    "        if contour.size > 6:  # Need at least 6 (3 points) to build a valid polygon\n",
    "            polygon = contour.flatten().tolist()  # Extract polygon list\n",
    "            polygons.append(polygon)\n",
    "\n",
    "visualize_polygon(img_path=test_img, polygons=polygons, color=(0, 255, 0, 255))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45959e7699af6de0f180a988fb12417ed6a3fc23822abbd1741e1ffb35b1ce05"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}