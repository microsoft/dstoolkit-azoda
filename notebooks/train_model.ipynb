{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Detection Model\n",
    "\n",
    "This notebook provides a basic introduction to submitting a detection model training to AML leveraging the azure_utils and tfod_utils packages in this repo.\n",
    "\n",
    "Before executing the code please ensure you have followed the setup in the wiki and ensured you have the following:\n",
    "- AML Workspace\n",
    "- Blob or fileshare containing images and label version files\n",
    "- Pretrained model from TF model zoo in the same storage\n",
    "- Built docker image registered to ACR\n",
    "- Local conda environment with the requirements and packages installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "from azure_utils.azure import load_config\n",
    "from azure_utils.experiment import AMLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Run Paramters\n",
    "\n",
    "Below sets the run paramters including the dockerfile path, base model and datasets. Note that if you datasets are in the same date naming convention you can use the latest keyword to automatically retrieve the latest version.\n",
    "\n",
    "For more information around the different parameters visit the wiki documentation: \"Model-Training.md\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run params    \n",
    "env_config_file = \"dev_config.json\"\n",
    "\n",
    "# Train with TensorFlow 1 use docker built from tf_1 - \"csaddevamlacr.azurecr.io/tfod_tf1:test\"\n",
    "# Train with TensorFlow 2 use docker built from tf_2 - \"csaddevamlacr.azurecr.io/tfod_tf2:test\"\n",
    "docker_image = \"csaddevamlacr.azurecr.io/tfod_tf2:test\"\n",
    "\n",
    "# Train with TF1 use - \"train.py\"\n",
    "# Train with TF2 use - \"train_tf2.py\"\n",
    "training_script_name = \"train_tf2.py\"\n",
    "\n",
    "# Description\n",
    "desc = \"Add description here\"\n",
    "# Experiment name\n",
    "experiment_name = \"pothole\"\n",
    "    \n",
    "# Training and test data selction\n",
    "store_name = \"test_data\"\n",
    "img_type = \"pothole\"\n",
    "train_csv = \"latest\"\n",
    "test_csv = \"latest\"\n",
    "\n",
    "# Base model Selection\n",
    "base_model = \"faster_rcnn_inception_resnet_v2_1024x1024_coco17_tpu-8\"\n",
    "\n",
    "# Model Params\n",
    "steps = 1000\n",
    "eval_conf = 0.5\n",
    "# If using TF1 use batch_size = 1\n",
    "batch_size = 1\n",
    "\n",
    "# Compute Params\n",
    "cluster_name = \"train-dev-2\"\n",
    "vm_type = \"STANDARD_NC6\"\n",
    "nodes = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialise Experiment Class\n",
    "\n",
    "Below creates and instance of the experiment class int he Azure utils package, it takes a config file to point to a speciifc AML workspace and the experiment name for usecase grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_exp = AMLExperiment(experiment_name, config_file=env_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set AML Datastore reference\n",
    "\n",
    "This package makes use of the old approach of mounting the entire datastore in order to access images, dataset files and base models. Below sets up the defined datastore to mount on execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_exp.set_datastore(store_name)\n",
    "aml_exp.set_data_reference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create/Set Compute\n",
    "\n",
    "Below checks if a compute with the provided name exists in the AML workspace and if not creates based on the spec. It takes arguments for node count and vm type with the base compute set to \"STANDARD_NC\" in order to provide GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_exp.set_compute(cluster_name, vm_type=vm_type, node_count=nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Set script params and path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_params = [\n",
    "    '--desc', desc,\n",
    "    '--data_dir', str(aml_exp.data_ref),\n",
    "    '--image_type', img_type,\n",
    "    '--train_csv', train_csv,\n",
    "    '--test_csv', test_csv,\n",
    "    '--base_model', base_model,\n",
    "    '--steps', steps,\n",
    "    '--eval_conf', eval_conf,\n",
    "    '--batch_size', batch_size]\n",
    "\n",
    "# Copy train file to /notebooks\n",
    "shutil.copy(os.path.join(r'..\\src\\training\\scripts', training_script_name), os.path.join('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Run Config\n",
    "\n",
    "Create run config brings together the compute, script , params and docker image to form a script run configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts = os.path.join('.')\n",
    "aml_exp.set_runconfig(scripts,\n",
    "                      training_script_name,\n",
    "                      script_params,\n",
    "                      docker_image=docker_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Submit\n",
    "\n",
    "Finally execute the configuration defined above to AML. The execution can then be monitored from the AML studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_exp.submit_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "45959e7699af6de0f180a988fb12417ed6a3fc23822abbd1741e1ffb35b1ce05"
  },
  "kernelspec": {
   "display_name": "dstkpy37",
   "language": "python",
   "name": "dstkpy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
