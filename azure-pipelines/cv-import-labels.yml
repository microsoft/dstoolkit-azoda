name: Import labels from Custom Vision

trigger: none

pool:
  vmImage: ubuntu-20.04

variables:
- group: vars

steps:
- task: AzureCLI@2
  inputs:
    azureSubscription: 'ARMSC'
    scriptType: 'bash'
    scriptLocation: 'inlineScript'
    inlineScript: |
      echo '--- Installing required libraries ---'
      az config set extension.use_dynamic_install=yes_without_prompt

      pip install azureml-sdk==1.39.0
      az extension add -n ml -y
      pip install --index-url https://pkgs.dev.azure.com/watchfor/WatchForTools/_packaging/w4Tools/pypi/simple/ watchfor-pixiev3==0.3.16
      sudo apt install ffmpeg -y
      pip uninstall ffmpeg-python -y
      pip install numpy pandas azure-cognitiveservices-vision-customvision tqdm pascal_voc_writer opencv-python-headless Pillow

      echo '--- Setting variables ---'
      cv_name=azodacv
      workspace_name=azoda-amlw
      resource_group=azoda-rg
      subscription_id_str=$(az account list --query "[?isDefault].id | [0]")
      subscription_id=$(echo $subscription_id_str | tr -d \")
      aml_storage_account_name_str=$(az ml datastore list --resource-group $resource_group --workspace-name $workspace_name --query "sort_by([].{account_name:account_name}[? contains(account_name, 'azoda')], &account_name)"[0].account_name)
      aml_storage_account_name=$(echo $aml_storage_account_name_str | tr -d \")
      aml_container_str=$(az ml datastore show --name workspaceblobstore --resource-group $resource_group --workspace-name $workspace_name --query container_name)
      aml_container=$(echo $aml_container_str | tr -d \")

      echo '--- Download dataset ---'
      cd src/auto_setup
      az storage blob directory download -c $aml_container --account-name $aml_storage_account_name -s $(dataset)/ -d "." --recursive

      echo '--- Import new labels from Custom Vision project ---'
      output_dir=azoda_test_output
      cv_key=$(echo $(az keyvault secret show --vault-name azoda-kv --name cvkey | jq -r ".value"))
      python import_dataset_from_cv.py --key $cv_key --cv_name $cv_name --output_dir "temp" --dataset $(dataset)

      echo '--- Create train test split ---'
      python create_dataset_splits.py --dataset $(dataset)

      echo '--- Move dataset csv files to the datasets directory'
      mv *.csv $(dataset)/datasets/

      echo '--- Convert to yolo annotations ---'
      python tf_to_yolo_annotations.py --dataset $(dataset)

      echo '--- Upload results to datastore ---'
      az storage blob directory upload -c $aml_container --account-name $aml_storage_account_name -s '$(dataset)/datasets/*.csv' -d '$(dataset)/datasets'
